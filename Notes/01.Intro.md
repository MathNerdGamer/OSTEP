# Introduction to Operating Systems

* When a program runs, it does three things (ignoring a bunch of extra stuff done for performance):
    1. It *fetches* an instruction from memory.
    2. It *decodes* the instruction.
    3. It *executes* the instruction.
    4. Then, it starts from the beginning for the next instruction.
    * This is known as the *von Neumann* model of computing, named after John von Neumann.

* An *operating system* is essentially software that makes it easy to run programs.

* An operating system does this is by employing a technique known as *virtualization*.
    * Virtualization is taking a physical resource and abstracting away the implementation details to its most fundamental form.
    * As a result, operating systems are sometimes called *virtual machines* (as opposed to something like VirtualBox, which is technically a *virtual machine monitor*, or *hypervisor*).
    * Figuring out how an operating system might do this is one of the main goals of this course.

* In order for users to make use of the OS, *interfaces* (aka *APIs*) are provided in the form of a *system call* (*syscall*).
    * A few hundred syscalls may be provided by an OS.
    * These syscalls allow for practically all of the things an OS is made for, such as running programs, accessing memory or devices, or anything else that needs the OS to provide that layer of abstraction for access to physical hardware.
    * As a result, an operating system is said to provide a *standard library* for such actions.

* Since virtualization allows for shared use of system resources, an OS is sometimes referred to ask a *resource manager*.
    * Resources include, but are not limited to, CPU time for running a program (or, more commonly, **many** programs concurrently) and access to hardware attached to the system in the form of persistent storage, extra compute units (i.e., a GPU), or networking.
    * The operating system, in an attempt to keep some semblance of order in all of the chaos, has to manage these resources carefully and efficiently.

## Virtualizing the CPU

File: `cpu.c`
```c
#include <stdio.h>
#include <stdlib.h>
#include "common.h"

int main(int argc, char *argv[])
{
    if (argc != 2) {
	fprintf(stderr, "usage: cpu <string>\n");
	exit(1);
    }
    char *str = argv[1];

    while (1) {
	printf("%s\n", str);
	Spin(1);
    }
    return 0;
}
```

* The above code is our first example.
    * All it does is loop forever printing a string out and calling `Spin()`.
    * What does `Spin()` even do?

File: `common.h`
```c
#ifndef __common_h__
#define __common_h__

#include <sys/time.h>
#include <sys/stat.h>
#include <assert.h>

double GetTime() {
    struct timeval t;
    int rc = gettimeofday(&t, NULL);
    assert(rc == 0);
    return (double) t.tv_sec + (double) t.tv_usec/1e6;
}

void Spin(int howlong) {
    double t = GetTime();
    while ((GetTime() - t) < (double) howlong)
	; // do nothing in loop
}

#endif // __common_h__
```

* Taking a look at the `common.h` header file, it seems `Spin()` takes an integer and, for the number of seconds specified by that integer, does nothing.

* When we run `./cpu A`, we get the following output:
    ```
    shell> ./cpu A
    A
    A
    A
    A
    ^C
    shell>
    ```
    * Here, we used `CTRL+C` to end execution.

* What about if we use `&` to start multiple versions of `./cpu` with different arguments?
    ```
    shell> ./cpu A & ./cpu B & ./cpu C & ./cpu D &
    [1] 14570
    [2] 14571
    [3] 14572
    [4] 14573
    A
    B
    C
    D
    A
    B
    C
    D
    . . .
    kill 14570 & kill 14571 & kill 14572 & kill 14573
    ```
    * Make note of the *pid* of each command so that they can be killed, or else it'll just go on forever.
    * `CTRL+C` won't work here.

* Note that we get multiple versions of our command running concurrently.
    * How the operating system decides how and when each command gets turn executing will be covered later.
    * Such decision-making is known as a *policy*.
    * It's through the policy specified by the operating system that multiple programs can share the CPU to execute.

* Allowing for multiple programs to run at seemingly the same time is an example of the operating system *virtualizing the CPU*.

## Virtualizing Memory

* Operating systems also *virtualize memory*.
    * Operating systems specify a simplistic model for *physical memory*:
        * Memory is an array of bytes.
        * To *read* from memory, one must specify an *address*.
        * To *write* (or *update*) memory, one must specify both an address and the data to be written.

* Recall that, in the von Neumann model, both the data we're operating on **and** the instructions of our program are in memory.

File: `mem.c`
```c
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include "common.h"

int main(int argc, char *argv[]) {
    if (argc != 2) { 
	    fprintf(stderr, "usage: mem <value>\n"); 
	    exit(1); 
    } 
    int *p; 
    p = malloc(sizeof(int));
    assert(p != NULL);
    printf("(%d) addr pointed to by p: %p\n", (int) getpid(), p);
    *p = atoi(argv[1]); // assign value to addr stored in p
    while (1) {
	    Spin(1);
	    *p = *p + 1;
	    printf("(%d) value of p: %d\n", getpid(), *p);
    }
    return 0;
}
```

* Looking at `mem.c`:
    * We allocate an `int` on the heap and assign the address to pointer `p`.
    * In an infinite loop, we spin for a second, increment the integer pointed to by `p`, and print it out.

* Below is an example output.
    ```
    shell> ./mem 0
    (20119) addr pointed to by p: 0x5555555592a0
    (20119) value of p: 1
    (20119) value of p: 2
    (20119) value of p: 3
    (20119) value of p: 4
    (20119) value of p: 5
    (20119) value of p: 6
    (20119) value of p: 7
    (20119) value of p: 8
    (20119) value of p: 9
    ^C
    shell>
    ```

* If we run multiple instances of this, we'll notice something interesting.
    ```
    shell> ./mem 0 & ./mem 10 &
    [1] 21459
    [2] 21460
    (21459) addr pointed to by p: 0x5555555592a0
    (21460) addr pointed to by p: 0x5555555592a0
    (21459) value of p: 1
    (21460) value of p: 11
    (21459) value of p: 2
    (21460) value of p: 12
    (21459) value of p: 3
    (21460) value of p: 13
    (21459) value of p: 4
    (21460) value of p: 14
    . . .
    kill 21459 & kill 21460
    ```

* Notice that the addresses were the same, even though the programs clearly see different values at that address.
    * This is a result of memory virtualization.
    * Each program gets its own private *virtual memory address space* (or just *address space*).
    * They are isolated in their own chunks of memory, and they can run as though they have all of physical memory without worrying about stepping on another program's memory.

* The above examples were run with a security feature, *Address Space Layout Randomization* (*ASLR*), disabled.
    * To emulate this, run `echo 0 | sudo tee /proc/sys/kernel/randomize_va_space`.
    * However, be *absolutely sure* that you re-enable full randomization afterwards using `echo 2 | sudo tee /proc/sys/kernel/randomize_va_space`.
    * If we were to run without disabling ASLR, the addresses would be different, which wouldn't demonstrate memory virtualization very well.
    * There are legitimate security reasons for why, despite each program having their own address spaces, it's still necessary to have them point to random (and probably different) addresses as the start of their stacks.
        * See: [Stack Buffer Overflow](https://en.wikipedia.org/wiki/Stack_buffer_overflow)

## Concurrency

* *Concurrency* is the ability of programs to execute instructions in segments where we may interrupt one segment to allow for the execution of a different segment.
    * For example, we may have two tasks that might have some level of inter-dependence, but can be executed in such a way that, when one task has to wait (such as for some I/O operation), the other task can start from where it previously stopped.
    * This allows for less time spent with the CPU doing nothing -- or worse, spending cycles, and the accompanying electricity, just to wait.

* The first examples of concurrency come from operating systems, themselves.
    * Recall that we've been running multiple versions of the example code above where the execution seemingly overlapped.
    * This is a result of the operating system using concurrency to make efficient use of the CPU to stop working on one program when it runs into the `Spin()` function to work on the next.

* The problems that come with concurrency can be quite difficult to wrap one's head around and, nowadays, are involved in more than just the operating system.
    * Many programs are now *multi-threaded*.
    * We see an example of a multi-threaded program below, along with a problem that arises due to a bug that might not be obvious on first inspection, especially when first seeing threads.

File: `threads.c`
```c
#include <stdio.h>
#include <stdlib.h>
#include "common.h"
#include "common_threads.h"

volatile int counter = 0; 
int loops;

void *worker(void *arg) {
    int i;
    for (i = 0; i < loops; i++) {
	counter++;
    }
    return NULL;
}

int main(int argc, char *argv[]) {
    if (argc != 2) { 
	fprintf(stderr, "usage: threads <loops>\n"); 
	exit(1); 
    } 
    loops = atoi(argv[1]);
    pthread_t p1, p2;
    printf("Initial value : %d\n", counter);
    Pthread_create(&p1, NULL, worker, NULL); 
    Pthread_create(&p2, NULL, worker, NULL);
    Pthread_join(p1, NULL);
    Pthread_join(p2, NULL);
    printf("Final value   : %d\n", counter);
    return 0;
}
```

* Note that there's an included `common_threads.h` header, but this just defines some wrapper macros for some of the functions being used.
    * In particular, `Pthread_create()` and `Pthread_join()` are wrappers for the functions `pthread_create()` and `pthread_join()`, where the "p" is lowercase.
    * The details aren't very important for this example.

* This program creates two *threads*.
    * A thread can be thought of as a separate, but parallel, line of execution.
        * Parallel, here, should not be mistaken for *parallelism*.
            * Think of concurrency as a list of tasks that can be worked on where we can switch our attention between them as necessary.
            * Think of parallelism as having multiple workers doing these tasks simultaneously.
    * Multiple threads, then, allow for multiple lines of execution which may or may not converge at some point.

* These two threads work to add one to a counter some number of times, as specified by the arguments we pass to the program.
    * Two threads are adding 1 to a counter that starts at 0 a total of $N$ times each, where $N$ is the number we pass, and so we expect the output to be $2N$.

* It may not seem obvious at this point, but there is a bug in this program.
    * Let's look at a few executions.

```
shell> ./threads 100
Initial value : 0
Final value   : 200
shell> ./threads 1000
Initial value : 0
Final value   : 2000
shell> ./threads 10000
Initial value : 0
Final value   : 20000
```

* So far, so good, but what happens if we add one more 0 to the end?

```
shell> ./threads 100000
Initial value : 0
Final value   : 163963
```

* What happened here!?
    * Maybe it was a fluke?
    * Let's run a couple more times.

```
shell> ./threads 100000
Initial value : 0
Final value   : 198655
shell> ./threads 100000
Initial value : 0
Final value   : 200000
shell> ./threads 100000
Initial value : 0
Final value   : 188275
```

* Each time gives a different answer, and we even got lucky and saw the correct answer once.

* What's happening is that we're sharing a counter between the two threads.
    * The first few numbers we passed to the program were small enough for one thread to finish executing before the next started.
    * The last number, however, was large enough that there were context switches between the two threads mid-execution.
    * As a result, the two threads would end up seeing different values in the counter.
        * Suppose thread 1 saw a value of `12345` and the context switched to thread 2.
        * Thread 2 now sees `12345` in the counter and increments from there for awhile, and then we return to thread 1.
        * Thread 1 starts incrementing from `12345`, since that's the value it saw last, losing all of the progress that thread 2 had made.

* This is known as a *race condition* (or *race hazard*), specifically a *data race*, and is the result of our code not executing *atomically*.
    * This will be studied more in-depth when we get to the piece about concurrency.

## Persistence

* 